Multi-Node Kubernetes Cluster Setup:
Architektur:
Master Node: 192.168.1.101 (Control Plane)
Worker Node: 192.168.1.110 (Worker)
Cluster: Multi-Node k3s Cluster




1. Master Node Setup (192.168.1.101):
# Auf dem Master Server (192.168.1.101)
curl -sfL https://get.k3s.io | sh -s - server \
  --cluster-init \
  --write-kubeconfig-mode 644 \
  --tls-san 192.168.1.101 \
  --bind-address 192.168.1.101

# Als sudo (oder direkt als root)
sudo curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Token für Worker Nodes anzeigen
sudo cat /var/lib/rancher/k3s/server/node-token

2. Worker Node Setup (192.168.1.110):

# Auf dem Worker Server (192.168.1.110)
# Verwenden Sie das Token vom Master
curl -sfL https://get.k3s.io | K3S_URL=https://192.168.1.101:6443 \
  K3S_TOKEN=<TOKEN_VOM_MASTER> sh -

# Status prüfen
sudo systemctl status k3s-agent

# Auf dem Master Server

# Cluster Status prüfen
kubectl get nodes

# Config erstellen
mkdir -p ~/.kube
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config

# Cluster tests
# Nodes anzeigen
kubectl get nodes -o wide

# Namespaces anzeigen
kubectl get namespaces

# Services anzeigen
kubectl get services --all-namespaces

# Namespaces erstellen
kubectl create namespaceX
...


3. Add-ons (schlank, nach Basis-Setup)

# Kontext: Das Multi-Node k3s Basis-Setup (Control Plane 192.168.1.101, Worker 192.168.1.110)
# wurde bereits gemäß obigen Schritten durchgeführt.

# a) Netzwerk (ein Tool): NGINX Ingress Controller
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update
kubectl create namespace ingress-nginx --dry-run=client -o yaml | kubectl apply -f -
helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
  -n ingress-nginx \
  --set controller.metrics.enabled=true

# b) Speicher (ein Tool): local-path-provisioner (Hinweis: k3s bringt das bereits mit)
# Für k3s ist keine Aktion nötig. Für andere Kubernetes-Distributionen optional:
# helm repo add rancher-lpp https://rancher.github.io/local-path-provisioner/
# helm upgrade --install local-path-provisioner rancher-lpp/local-path-provisioner \
#   -n storage --create-namespace

# c) Monitoring (ein Tool): kube-prometheus-stack (Prometheus, Alertmanager, Grafana)
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
  -n monitoring

# (Optional) Grafana Zugriff lokal testen
# kubectl -n monitoring port-forward svc/kube-prometheus-stack-grafana 3000:80
# Browser: http://localhost:3000

# d) Meine Wahl (ein Tool): metrics-server (ermöglicht kubectl top / HPA)
kubectl create namespace kube-system --dry-run=client -o yaml | kubectl apply -f -
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Hinweis für k3s/Edge-Umgebungen: Falls kubelet-CA/Certs fehlen, starte metrics-server mit unsicherem TLS zum Testen:
# kubectl -n kube-system patch deploy metrics-server \
#   --type='json' \
#   -p='[{"op":"add","path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure-tls"}]'

# Verifikation
kubectl get pods -n ingress-nginx
kubectl get pods -n monitoring
kubectl top nodes

# CI/CD: Diese Add-ons können automatisiert deployed werden über
# GitHub Actions Workflow: .github/workflows/deploy-addons.yml
# Script: infra/addons/deploy.sh (nutzt Werte aus infra/addons/values/*)